{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40515c62",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-20T23:04:58.167686Z",
     "iopub.status.busy": "2025-01-20T23:04:58.167320Z",
     "iopub.status.idle": "2025-01-20T23:04:59.160379Z",
     "shell.execute_reply": "2025-01-20T23:04:59.159354Z"
    },
    "papermill": {
     "duration": 0.999121,
     "end_time": "2025-01-20T23:04:59.162361",
     "exception": false,
     "start_time": "2025-01-20T23:04:58.163240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas is a libaray that used to work with datasets\n",
    "import numpy as np # Manipulating arrays\n",
    "from matplotlib import pyplot as plt #Pyplot exists as a module inside the mathplotlib (not a standalone package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a384c200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:04:59.169191Z",
     "iopub.status.busy": "2025-01-20T23:04:59.168650Z",
     "iopub.status.idle": "2025-01-20T23:05:04.694157Z",
     "shell.execute_reply": "2025-01-20T23:05:04.692937Z"
    },
    "papermill": {
     "duration": 5.530711,
     "end_time": "2025-01-20T23:05:04.696086",
     "exception": false,
     "start_time": "2025-01-20T23:04:59.165375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 1)\n",
      "(9999, 784)\n",
      "9999 784\n"
     ]
    }
   ],
   "source": [
    "#using the training data, train our neural network\n",
    "\n",
    "data = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\n",
    "\n",
    "data = np.array(data) #covert pandas dataframe into ndarray- now a 2D array (60,000, 784)\n",
    "\n",
    "\n",
    "#Assign X and Y \n",
    "Y = data[1:10000, 0:1]\n",
    "X = data[1:10000,1:]\n",
    "print (Y.shape)\n",
    "print(X.shape)\n",
    "m, n = X.shape\n",
    "print(m,n)\n",
    "\n",
    "#we want to transpose both of them to be able to work in our calculations\n",
    "Y = Y.T\n",
    "X = X.T\n",
    "\n",
    "#normalize X (input values)\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2c2a79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:05:04.702482Z",
     "iopub.status.busy": "2025-01-20T23:05:04.702138Z",
     "iopub.status.idle": "2025-01-20T23:05:04.712872Z",
     "shell.execute_reply": "2025-01-20T23:05:04.711456Z"
    },
    "papermill": {
     "duration": 0.015948,
     "end_time": "2025-01-20T23:05:04.714604",
     "exception": false,
     "start_time": "2025-01-20T23:05:04.698656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initalize our weights, and bias point as matrix\n",
    "# Input layer: 784, Hidden layer: 10, Output layer: 0-9\n",
    "\n",
    "'''\n",
    "What should be the dimentions of the matrix?\n",
    "\n",
    "1. Weights \n",
    "    a. Input -> Hidden layer (784, 10) \n",
    "    b. Hidden -> Output (10, 10)\n",
    "\n",
    "2. Bias\n",
    "    a. Hidden layer (10, 1)\n",
    "    b. Output layer (10, 1)\n",
    "'''\n",
    "# randn: produce random numbers between [0,1]\n",
    "#subtract 0.5 to generate negative values as well [-0.5,0.5]\n",
    "def initalize_parameters():\n",
    "    W1 = np.random.rand(10,784) - 0.5 # each row corresponds to the node's weight respect to the other 784 input layers\n",
    "    W2 = np.random.rand (10,10) - 0.5\n",
    "    B1 = np.random.rand (10,1) - 0.5\n",
    "    B2 = np.random.rand (10,1) - 0.5\n",
    "    return W1, W2, B1, B2\n",
    "\n",
    "#we want to use an activation function so that our output isn't just a linear combination of the input\n",
    "def sigmoid_activation(Z):\n",
    "    Z = 1/ (1+ np.exp(-Z))\n",
    "    return Z\n",
    "\n",
    "# We are using sigmoid activation\n",
    "# we also have to ensure that they are the same relative to eachother\n",
    "def softMax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "\n",
    "def forward_propgation(W1,W2,B1,B2,X): #where X is the 784 values of pixel image\n",
    "    Z1 = W1.dot(X) + B1 #let the hidden layer values W1: (10, 784) X: (784, 1) -> dimentions of (10,1)\n",
    "    A1 = sigmoid_activation(Z1)\n",
    "\n",
    "    Z2 = W2.dot(A1) + B2 #Output later W2: (10,10) A1: (10,1)-> Z2: (10,1)\n",
    "    A2 = softMax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "#one hot encoding: a way to tell your program which output should be right\n",
    "def one_hot_encode(Y): #Y is your answer vector in dimentions (Y.size, 1): row, coloumn\n",
    "    #turn your answer vector into a matrix\n",
    "    matrix = np.zeros((Y.size, Y.max() + 1))\n",
    "    matrix[np.arange(Y.size), Y] = 1 #arrange creates a array from 0 - Y.size-1, so then u can use to index\n",
    "    return matrix.T #matrix is now in dimentions (Y.size(), 10): row, coloumn\n",
    "\n",
    "# we use backward propogation to change the weights and biases, accoriding to input and expected output data\n",
    "def backward_propogation(Z1, A1, Z2, A2, W2, Y):\n",
    "    output_encoded = one_hot_encode(Y)\n",
    "    #keep track of all the small changes\n",
    "    dZ2 = A2 - output_encoded #the difference between expected and actual values\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    dB2 = 1 / m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * sigmoid_activation(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    dB1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, dB1, dW2, dB2\n",
    "\n",
    "def learn(W1, B1, W2, B2, dW1, dB1, dW2, dB2, alpha):\n",
    "    #we want to update the biases and weights, by the learning rate: alpha\n",
    "    W1 = W1 - alpha * dW1\n",
    "    B1 = B1 - alpha * dB1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    B2 = B2 - alpha * dB2    \n",
    "    return W1, B1, W2, B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7aa9096d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:05:04.721619Z",
     "iopub.status.busy": "2025-01-20T23:05:04.721290Z",
     "iopub.status.idle": "2025-01-20T23:05:04.725982Z",
     "shell.execute_reply": "2025-01-20T23:05:04.724886Z"
    },
    "papermill": {
     "duration": 0.010752,
     "end_time": "2025-01-20T23:05:04.727920",
     "exception": false,
     "start_time": "2025-01-20T23:05:04.717168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this will get the largest value from the output (what the neural network thinks the number is)\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y) #print the expected and actual\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4af226d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:05:04.735748Z",
     "iopub.status.busy": "2025-01-20T23:05:04.735394Z",
     "iopub.status.idle": "2025-01-20T23:05:04.741475Z",
     "shell.execute_reply": "2025-01-20T23:05:04.740472Z"
    },
    "papermill": {
     "duration": 0.011389,
     "end_time": "2025-01-20T23:05:04.743388",
     "exception": false,
     "start_time": "2025-01-20T23:05:04.731999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y,alpha, iterations):\n",
    "    #start with an inital value for weights and biases\n",
    "    W1, W2, B1, B2 = initalize_parameters()\n",
    "\n",
    "    for i in range (iterations):\n",
    "        #we want to first forward propogate\n",
    "        Z1, A1, Z2, A2= forward_propgation(W1,W2,B1,B2,X) \n",
    "        #back propogation to update out weights and biases\n",
    "        dW1, dB1, dW2, dB2 = backward_propogation(Z1, A1, Z2, A2, W2, Y)\n",
    "        #depending on the error - change the value of weights and biases\n",
    "        W1, b1, W2, b2= learn(W1, B1, W2, B2, dW1, dB1, dW2, dB2, alpha)\n",
    "        #we only want to print every 100 iterations\n",
    "        if i%100 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, B1, W2, B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5fc1bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:05:04.749680Z",
     "iopub.status.busy": "2025-01-20T23:05:04.749351Z",
     "iopub.status.idle": "2025-01-20T23:06:40.114146Z",
     "shell.execute_reply": "2025-01-20T23:06:40.113166Z"
    },
    "papermill": {
     "duration": 95.370202,
     "end_time": "2025-01-20T23:06:40.116235",
     "exception": false,
     "start_time": "2025-01-20T23:05:04.746033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[6 6 6 ... 6 2 2] [[0 4 1 ... 6 9 7]]\n",
      "0.0852085208520852\n",
      "Iteration:  100\n",
      "[0 6 1 ... 1 9 9] [[0 4 1 ... 6 9 7]]\n",
      "0.3684368436843684\n",
      "Iteration:  200\n",
      "[0 7 1 ... 1 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.3708370837083708\n",
      "Iteration:  300\n",
      "[0 4 1 ... 1 9 9] [[0 4 1 ... 6 9 7]]\n",
      "0.38793879387938796\n",
      "Iteration:  400\n",
      "[0 4 1 ... 1 9 9] [[0 4 1 ... 6 9 7]]\n",
      "0.40404040404040403\n",
      "Iteration:  500\n",
      "[0 4 1 ... 2 9 9] [[0 4 1 ... 6 9 7]]\n",
      "0.45454545454545453\n",
      "Iteration:  600\n",
      "[0 4 1 ... 2 9 9] [[0 4 1 ... 6 9 7]]\n",
      "0.45064506450645064\n",
      "Iteration:  700\n",
      "[0 4 1 ... 2 9 9] [[0 4 1 ... 6 9 7]]\n",
      "0.45584558455845586\n",
      "Iteration:  800\n",
      "[0 4 1 ... 8 3 9] [[0 4 1 ... 6 9 7]]\n",
      "0.4823482348234823\n",
      "Iteration:  900\n",
      "[0 4 1 ... 8 3 9] [[0 4 1 ... 6 9 7]]\n",
      "0.4878487848784879\n",
      "Iteration:  1000\n",
      "[0 4 1 ... 8 3 9] [[0 4 1 ... 6 9 7]]\n",
      "0.49784978497849786\n",
      "Iteration:  1100\n",
      "[0 4 1 ... 8 3 9] [[0 4 1 ... 6 9 7]]\n",
      "0.5138513851385138\n",
      "Iteration:  1200\n",
      "[0 4 1 ... 8 3 9] [[0 4 1 ... 6 9 7]]\n",
      "0.5177517751775178\n",
      "Iteration:  1300\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5229522952295229\n",
      "Iteration:  1400\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5298529852985299\n",
      "Iteration:  1500\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.536953695369537\n",
      "Iteration:  1600\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5403540354035403\n",
      "Iteration:  1700\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5456545654565457\n",
      "Iteration:  1800\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.551055105510551\n",
      "Iteration:  1900\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5558555855585559\n",
      "Iteration:  2000\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5601560156015601\n",
      "Iteration:  2100\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5628562856285628\n",
      "Iteration:  2200\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5688568856885688\n",
      "Iteration:  2300\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5726572657265726\n",
      "Iteration:  2400\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5816581658165817\n",
      "Iteration:  2500\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5874587458745875\n",
      "Iteration:  2600\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5902590259025903\n",
      "Iteration:  2700\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5934593459345935\n",
      "Iteration:  2800\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5966596659665967\n",
      "Iteration:  2900\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6014601460146015\n",
      "Iteration:  3000\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6036603660366037\n",
      "Iteration:  3100\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6062606260626062\n",
      "Iteration:  3200\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6076607660766077\n",
      "Iteration:  3300\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6107610761076108\n",
      "Iteration:  3400\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6134613461346134\n",
      "Iteration:  3500\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6154615461546155\n",
      "Iteration:  3600\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6177617761776177\n",
      "Iteration:  3700\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6190619061906191\n",
      "Iteration:  3800\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6208620862086208\n",
      "Iteration:  3900\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6245624562456246\n",
      "Iteration:  4000\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6266626662666267\n",
      "Iteration:  4100\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6347634763476347\n",
      "Iteration:  4200\n",
      "[0 4 1 ... 8 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6362636263626362\n",
      "Iteration:  4300\n",
      "[0 4 1 ... 6 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6375637563756376\n",
      "Iteration:  4400\n",
      "[0 4 1 ... 6 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6391639163916392\n",
      "Iteration:  4500\n",
      "[0 4 1 ... 6 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6393639363936393\n",
      "Iteration:  4600\n",
      "[0 4 1 ... 6 3 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6402640264026402\n",
      "Iteration:  4700\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6481648164816481\n",
      "Iteration:  4800\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6478647864786479\n",
      "Iteration:  4900\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6505650565056506\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X, Y, 0.10, 5000)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 27352,
     "sourceId": 34877,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.413697,
   "end_time": "2025-01-20T23:06:40.741761",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-20T23:04:55.328064",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
