{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bc4f66",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-20T23:10:26.478106Z",
     "iopub.status.busy": "2025-01-20T23:10:26.477728Z",
     "iopub.status.idle": "2025-01-20T23:10:27.391765Z",
     "shell.execute_reply": "2025-01-20T23:10:27.391032Z"
    },
    "papermill": {
     "duration": 0.919752,
     "end_time": "2025-01-20T23:10:27.393533",
     "exception": false,
     "start_time": "2025-01-20T23:10:26.473781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas is a libaray that used to work with datasets\n",
    "import numpy as np # Manipulating arrays\n",
    "from matplotlib import pyplot as plt #Pyplot exists as a module inside the mathplotlib (not a standalone package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7793084c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:10:27.399232Z",
     "iopub.status.busy": "2025-01-20T23:10:27.398798Z",
     "iopub.status.idle": "2025-01-20T23:10:32.124944Z",
     "shell.execute_reply": "2025-01-20T23:10:32.123889Z"
    },
    "papermill": {
     "duration": 4.730557,
     "end_time": "2025-01-20T23:10:32.126738",
     "exception": false,
     "start_time": "2025-01-20T23:10:27.396181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999, 1)\n",
      "(9999, 784)\n",
      "9999 784\n"
     ]
    }
   ],
   "source": [
    "#using the training data, train our neural network\n",
    "\n",
    "data = pd.read_csv('/kaggle/input/mnist-in-csv/mnist_train.csv')\n",
    "\n",
    "data = np.array(data) #covert pandas dataframe into ndarray- now a 2D array (60,000, 784)\n",
    "\n",
    "\n",
    "#Assign X and Y \n",
    "Y = data[1:10000, 0:1]\n",
    "X = data[1:10000,1:]\n",
    "print (Y.shape)\n",
    "print(X.shape)\n",
    "m, n = X.shape\n",
    "print(m,n)\n",
    "\n",
    "#we want to transpose both of them to be able to work in our calculations\n",
    "Y = Y.T\n",
    "X = X.T\n",
    "\n",
    "#normalize X (input values)\n",
    "X = X / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cbab2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:10:32.132369Z",
     "iopub.status.busy": "2025-01-20T23:10:32.132044Z",
     "iopub.status.idle": "2025-01-20T23:10:32.141957Z",
     "shell.execute_reply": "2025-01-20T23:10:32.141194Z"
    },
    "papermill": {
     "duration": 0.014115,
     "end_time": "2025-01-20T23:10:32.143272",
     "exception": false,
     "start_time": "2025-01-20T23:10:32.129157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#initalize our weights, and bias point as matrix\n",
    "# Input layer: 784, Hidden layer: 10, Output layer: 0-9\n",
    "\n",
    "'''\n",
    "What should be the dimentions of the matrix?\n",
    "\n",
    "1. Weights \n",
    "    a. Input -> Hidden layer (784, 10) \n",
    "    b. Hidden -> Output (10, 10)\n",
    "\n",
    "2. Bias\n",
    "    a. Hidden layer (10, 1)\n",
    "    b. Output layer (10, 1)\n",
    "'''\n",
    "# randn: produce random numbers between [0,1]\n",
    "#subtract 0.5 to generate negative values as well [-0.5,0.5]\n",
    "def initalize_parameters():\n",
    "    W1 = np.random.rand(10,784) - 0.5 # each row corresponds to the node's weight respect to the other 784 input layers\n",
    "    W2 = np.random.rand (10,10) - 0.5\n",
    "    B1 = np.random.rand (10,1) - 0.5\n",
    "    B2 = np.random.rand (10,1) - 0.5\n",
    "    return W1, W2, B1, B2\n",
    "\n",
    "#we want to use an activation function so that our output isn't just a linear combination of the input\n",
    "def sigmoid_activation(Z):\n",
    "    Z = 1/ (1+ np.exp(-Z))\n",
    "    return Z\n",
    "\n",
    "# We are using sigmoid activation\n",
    "# we also have to ensure that they are the same relative to eachother\n",
    "def softMax(Z):\n",
    "    A = np.exp(Z) / sum(np.exp(Z))\n",
    "    return A\n",
    "\n",
    "\n",
    "def forward_propgation(W1,W2,B1,B2,X): #where X is the 784 values of pixel image\n",
    "    Z1 = W1.dot(X) + B1 #let the hidden layer values W1: (10, 784) X: (784, 1) -> dimentions of (10,1)\n",
    "    A1 = sigmoid_activation(Z1)\n",
    "\n",
    "    Z2 = W2.dot(A1) + B2 #Output later W2: (10,10) A1: (10,1)-> Z2: (10,1)\n",
    "    A2 = softMax(Z2)\n",
    "    return Z1, A1, Z2, A2\n",
    "\n",
    "#one hot encoding: a way to tell your program which output should be right\n",
    "def one_hot_encode(Y): #Y is your answer vector in dimentions (Y.size, 1): row, coloumn\n",
    "    #turn your answer vector into a matrix\n",
    "    matrix = np.zeros((Y.size, Y.max() + 1))\n",
    "    matrix[np.arange(Y.size), Y] = 1 #arrange creates a array from 0 - Y.size-1, so then u can use to index\n",
    "    return matrix.T #matrix is now in dimentions (Y.size(), 10): row, coloumn\n",
    "\n",
    "# we use backward propogation to change the weights and biases, accoriding to input and expected output data\n",
    "def backward_propogation(Z1, A1, Z2, A2, W2, Y):\n",
    "    output_encoded = one_hot_encode(Y)\n",
    "    #keep track of all the small changes\n",
    "    dZ2 = A2 - output_encoded #the difference between expected and actual values\n",
    "    dW2 = 1 / m * dZ2.dot(A1.T)\n",
    "    dB2 = 1 / m * np.sum(dZ2)\n",
    "    dZ1 = W2.T.dot(dZ2) * sigmoid_activation(Z1)\n",
    "    dW1 = 1 / m * dZ1.dot(X.T)\n",
    "    dB1 = 1 / m * np.sum(dZ1)\n",
    "    return dW1, dB1, dW2, dB2\n",
    "\n",
    "def learn(W1, B1, W2, B2, dW1, dB1, dW2, dB2, alpha):\n",
    "    #we want to update the biases and weights, by the learning rate: alpha\n",
    "    W1 = W1 - alpha * dW1\n",
    "    B1 = B1 - alpha * dB1    \n",
    "    W2 = W2 - alpha * dW2  \n",
    "    B2 = B2 - alpha * dB2    \n",
    "    return W1, B1, W2, B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5e738a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:10:32.148389Z",
     "iopub.status.busy": "2025-01-20T23:10:32.148113Z",
     "iopub.status.idle": "2025-01-20T23:10:32.152110Z",
     "shell.execute_reply": "2025-01-20T23:10:32.151301Z"
    },
    "papermill": {
     "duration": 0.00798,
     "end_time": "2025-01-20T23:10:32.153441",
     "exception": false,
     "start_time": "2025-01-20T23:10:32.145461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this will get the largest value from the output (what the neural network thinks the number is)\n",
    "def get_predictions(A2):\n",
    "    return np.argmax(A2, 0)\n",
    "\n",
    "def get_accuracy(predictions, Y):\n",
    "    print(predictions, Y) #print the expected and actual\n",
    "    return np.sum(predictions == Y) / Y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a446abb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:10:32.159850Z",
     "iopub.status.busy": "2025-01-20T23:10:32.159607Z",
     "iopub.status.idle": "2025-01-20T23:10:32.164776Z",
     "shell.execute_reply": "2025-01-20T23:10:32.164007Z"
    },
    "papermill": {
     "duration": 0.009318,
     "end_time": "2025-01-20T23:10:32.166318",
     "exception": false,
     "start_time": "2025-01-20T23:10:32.157000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X,Y,alpha, iterations):\n",
    "    #start with an inital value for weights and biases\n",
    "    W1, W2, B1, B2 = initalize_parameters()\n",
    "\n",
    "    for i in range (iterations):\n",
    "        #we want to first forward propogate\n",
    "        Z1, A1, Z2, A2= forward_propgation(W1,W2,B1,B2,X) \n",
    "        #back propogation to update out weights and biases\n",
    "        dW1, dB1, dW2, dB2 = backward_propogation(Z1, A1, Z2, A2, W2, Y)\n",
    "        #depending on the error - change the value of weights and biases\n",
    "        W1, b1, W2, b2= learn(W1, B1, W2, B2, dW1, dB1, dW2, dB2, alpha)\n",
    "        #we only want to print every 100 iterations\n",
    "        if i%100 == 0:\n",
    "            print(\"Iteration: \", i)\n",
    "            predictions = get_predictions(A2)\n",
    "            print(get_accuracy(predictions, Y))\n",
    "    return W1, B1, W2, B2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c22dfa96",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-20T23:10:32.171526Z",
     "iopub.status.busy": "2025-01-20T23:10:32.171287Z",
     "iopub.status.idle": "2025-01-20T23:12:45.624454Z",
     "shell.execute_reply": "2025-01-20T23:12:45.623266Z"
    },
    "papermill": {
     "duration": 133.457788,
     "end_time": "2025-01-20T23:12:45.626382",
     "exception": false,
     "start_time": "2025-01-20T23:10:32.168594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[2 2 2 ... 2 2 2] [[0 4 1 ... 6 9 7]]\n",
      "0.08830883088308832\n",
      "Iteration:  100\n",
      "[0 4 1 ... 8 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.474047404740474\n",
      "Iteration:  200\n",
      "[0 4 1 ... 8 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.5367536753675367\n",
      "Iteration:  300\n",
      "[0 4 1 ... 8 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.588058805880588\n",
      "Iteration:  400\n",
      "[0 4 1 ... 8 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6155615561556156\n",
      "Iteration:  500\n",
      "[0 4 1 ... 8 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6368636863686369\n",
      "Iteration:  600\n",
      "[0 4 1 ... 8 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.65006500650065\n",
      "Iteration:  700\n",
      "[0 4 1 ... 8 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6598659865986599\n",
      "Iteration:  800\n",
      "[0 4 1 ... 8 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6818681868186819\n",
      "Iteration:  900\n",
      "[0 4 1 ... 2 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.6934693469346934\n",
      "Iteration:  1000\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7044704470447045\n",
      "Iteration:  1100\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7142714271427143\n",
      "Iteration:  1200\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.727972797279728\n",
      "Iteration:  1300\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7361736173617361\n",
      "Iteration:  1400\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7425742574257426\n",
      "Iteration:  1500\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7531753175317532\n",
      "Iteration:  1600\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7583758375837584\n",
      "Iteration:  1700\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7634763476347635\n",
      "Iteration:  1800\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7682768276827683\n",
      "Iteration:  1900\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7713771377137714\n",
      "Iteration:  2000\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7762776277627763\n",
      "Iteration:  2100\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7766776677667767\n",
      "Iteration:  2200\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7787778777877787\n",
      "Iteration:  2300\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7813781378137814\n",
      "Iteration:  2400\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7811781178117811\n",
      "Iteration:  2500\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7835783578357836\n",
      "Iteration:  2600\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7840784078407841\n",
      "Iteration:  2700\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7835783578357836\n",
      "Iteration:  2800\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.782978297829783\n",
      "Iteration:  2900\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7820782078207821\n",
      "Iteration:  3000\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7811781178117811\n",
      "Iteration:  3100\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7807780778077807\n",
      "Iteration:  3200\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7803780378037803\n",
      "Iteration:  3300\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7786778677867787\n",
      "Iteration:  3400\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7774777477747775\n",
      "Iteration:  3500\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7764776477647765\n",
      "Iteration:  3600\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7763776377637763\n",
      "Iteration:  3700\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7744774477447744\n",
      "Iteration:  3800\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7757775777577758\n",
      "Iteration:  3900\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7737773777377738\n",
      "Iteration:  4000\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7714771477147715\n",
      "Iteration:  4100\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7724772477247724\n",
      "Iteration:  4200\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7756775677567757\n",
      "Iteration:  4300\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7777777777777778\n",
      "Iteration:  4400\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7733773377337734\n",
      "Iteration:  4500\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7736773677367736\n",
      "Iteration:  4600\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7748774877487749\n",
      "Iteration:  4700\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7784778477847785\n",
      "Iteration:  4800\n",
      "[0 4 1 ... 6 4 7] [[0 4 1 ... 6 9 7]]\n",
      "0.7790779077907791\n",
      "Iteration:  4900\n",
      "[0 4 1 ... 6 9 7] [[0 4 1 ... 6 9 7]]\n",
      "0.780978097809781\n"
     ]
    }
   ],
   "source": [
    "W1, b1, W2, b2 = gradient_descent(X, Y, 0.7, 5000)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 27352,
     "sourceId": 34877,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 142.307004,
   "end_time": "2025-01-20T23:12:46.152160",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-20T23:10:23.845156",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
